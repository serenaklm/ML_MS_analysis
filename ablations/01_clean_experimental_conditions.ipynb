{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7318fd12",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24f158b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea5ad12",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29c758dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def write_json(data, path):\n",
    "    \n",
    "    with open(path, \"w\", encoding = \"UTF-8\") as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "def load_pickle(path):\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def to_binary(FP, threshold):\n",
    "\n",
    "    FP = (FP > threshold).astype(int)\n",
    "\n",
    "    return FP \n",
    "\n",
    "def jaccard_index(FP_pred, FP):\n",
    "\n",
    "    # Intersection = bitwise AND\n",
    "    intersection = np.logical_and(FP, FP_pred).sum()\n",
    "\n",
    "    # Union = bitwise OR\n",
    "    union = np.logical_or(FP, FP_pred).sum()\n",
    "\n",
    "    # Avoid division-by-zero by adding a small epsilon\n",
    "    jaccard = intersection / (union + 1e-9)\n",
    "\n",
    "    return jaccard\n",
    "\n",
    "def get_jaccard_score(results):\n",
    "        \n",
    "    total = 0 \n",
    "\n",
    "    for k, v in results.items():\n",
    "\n",
    "        pred = np.array(v[\"pred\"])\n",
    "        GT = v[\"GT\"]\n",
    "\n",
    "        pred = to_binary(pred, 0.5)\n",
    "        j = jaccard_index(pred, GT)\n",
    "\n",
    "        total += j \n",
    "\n",
    "    mean_score = total / len(results)\n",
    "\n",
    "    return mean_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae96de95",
   "metadata": {},
   "source": [
    "`` Let us look at how much training data is left when we only train with clean subset of the data ``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec14deb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>n_train (before)</th>\n",
       "      <th>n_train (after)</th>\n",
       "      <th>percentage drop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>massspecgym</td>\n",
       "      <td>inchikey_vanilla</td>\n",
       "      <td>76242</td>\n",
       "      <td>19437</td>\n",
       "      <td>74.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>massspecgym</td>\n",
       "      <td>scaffold_vanilla</td>\n",
       "      <td>76243</td>\n",
       "      <td>18942</td>\n",
       "      <td>75.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>massspecgym</td>\n",
       "      <td>random</td>\n",
       "      <td>75828</td>\n",
       "      <td>19263</td>\n",
       "      <td>74.596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nist2023</td>\n",
       "      <td>inchikey_vanilla</td>\n",
       "      <td>643637</td>\n",
       "      <td>48893</td>\n",
       "      <td>92.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nist2023</td>\n",
       "      <td>scaffold_vanilla</td>\n",
       "      <td>643637</td>\n",
       "      <td>48046</td>\n",
       "      <td>92.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nist2023</td>\n",
       "      <td>random</td>\n",
       "      <td>643521</td>\n",
       "      <td>48845</td>\n",
       "      <td>92.410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset             split  n_train (before)  n_train (after)  \\\n",
       "0  massspecgym  inchikey_vanilla             76242            19437   \n",
       "1  massspecgym  scaffold_vanilla             76243            18942   \n",
       "2  massspecgym            random             75828            19263   \n",
       "3     nist2023  inchikey_vanilla            643637            48893   \n",
       "4     nist2023  scaffold_vanilla            643637            48046   \n",
       "5     nist2023            random            643521            48845   \n",
       "\n",
       "   percentage drop  \n",
       "0           74.506  \n",
       "1           75.156  \n",
       "2           74.596  \n",
       "3           92.404  \n",
       "4           92.535  \n",
       "5           92.410  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = [] \n",
    "\n",
    "for dataset in [\"massspecgym\", \"nist2023\"]:\n",
    "\n",
    "    splits_folder = f\"/data/rbg/users/klingmin/projects/MS_processing/data_splits/{dataset}/splits\"\n",
    "\n",
    "    splits = [\"inchikey_vanilla\", \"scaffold_vanilla\", \"random\"]\n",
    "\n",
    "    for split in splits: \n",
    "\n",
    "        split_file = load_json(os.path.join(splits_folder, f\"{split}.json\"))\n",
    "        split_file_cleaned = load_json(os.path.join(splits_folder, f\"{split}_sieved.json\"))\n",
    "\n",
    "        train_ori, val_ori, test_ori = len(split_file[\"train\"]), len(split_file[\"val\"]), len(split_file[\"test\"])\n",
    "        train_new, val_new, test_new = len(split_file_cleaned[\"train\"]), len(split_file_cleaned[\"val\"]), len(split_file_cleaned[\"test\"])\n",
    "\n",
    "        percent_drop_train = round((train_ori - train_new) / train_ori * 100, 3)\n",
    "\n",
    "        table.append([dataset, split, train_ori, train_new, percent_drop_train])\n",
    "\n",
    "        print()\n",
    "\n",
    "table = pd.DataFrame(table)\n",
    "table.columns = [\"dataset\", \"split\", \"n_train (before)\", \"n_train (after)\", \"percentage drop\"]\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ee39e",
   "metadata": {},
   "source": [
    "`` Look at how the performance has changed based on the sampling strategy `` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ffc460e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSG_MIST_sieved_4096_scaffold_vanilla_sieved\n",
      "0.245 0.254\n",
      "\n",
      "MSG_MIST_sieved_4096_inchikey_vanilla_sieved\n",
      "0.276 0.29\n",
      "\n",
      "MSG_MIST_sieved_4096_random_sieved\n",
      "0.423 0.603\n",
      "\n",
      "NIST2023_MIST_sieved_4096_inchikey_vanilla_sieved\n",
      "0.304 0.302\n",
      "\n",
      "NIST2023_MIST_sieved_4096_random_sieved\n",
      "0.621 0.62\n",
      "\n",
      "NIST2023_MIST_sieved_4096_scaffold_vanilla_sieved\n",
      "0.257 0.257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"massspecgym\", \"nist2023\"]\n",
    "folder = \"../FP_prediction/mist/best_models\"\n",
    "\n",
    "for dataset in datasets:\n",
    "\n",
    "    sieved_folder = os.path.join(folder, f\"{dataset}_sieved\")\n",
    "    original_folder = os.path.join(folder, f\"{dataset}\")\n",
    "\n",
    "    for checkpoint in os.listdir(sieved_folder):\n",
    "        \n",
    "        original_checkpoint = [f for f in os.listdir(original_folder) if \"_\".join(checkpoint.split(\"_\")[-3:-1]) in f]\n",
    "        if len(original_checkpoint) == 0: continue\n",
    "        original_checkpoint = original_checkpoint[0]\n",
    "        \n",
    "        original_performance = load_json(os.path.join(original_folder, original_checkpoint, \"test_performance.json\"))\n",
    "        sieved_performance = load_json(os.path.join(sieved_folder, checkpoint, \"test_performance.json\"))[\"jaccard\"]\n",
    "\n",
    "        if \"jaccard_subset\" in original_performance: \n",
    "            original_results_subset_jaccard = original_performance[\"jaccard_subset\"] \n",
    "        \n",
    "        else:\n",
    "\n",
    "            sieved_results = load_pickle(os.path.join(sieved_folder, checkpoint, \"test_results.pkl\"))\n",
    "            sieved_keys = sieved_results.keys()\n",
    "            \n",
    "            original_results = load_pickle(os.path.join(original_folder, original_checkpoint, \"test_results.pkl\"))\n",
    "        \n",
    "            original_results_subset = {k: v for k,v in original_results.items() if k in sieved_keys}\n",
    "            original_results_subset_jaccard = get_jaccard_score(original_results_subset)\n",
    "\n",
    "            # Add in the performance of the subset into the original results \n",
    "            original_performance[\"jaccard_subset\"] = original_results_subset_jaccard\n",
    "            write_json(original_performance, os.path.join(original_folder, original_checkpoint, \"test_performance.json\"))\n",
    "\n",
    "        print(checkpoint)\n",
    "        print(round(sieved_performance,3), round(original_results_subset_jaccard,3))\n",
    "        print() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc51192",
   "metadata": {},
   "source": [
    "What are the influences - are they the molecules that look the same, or are they those with the same experimental conditions - are they outside of our influence groups. \n",
    "\n",
    "\n",
    "If our theory is right, we should see that positive influence that are same conditions. then negative influence are wrong conditions. \n",
    "\n",
    "We could think about conditions are similar - we can look at the particular influences; red on red - but now red on yellow \n",
    "\n",
    "Question: maybe there are some difference in conditions that are not important - even if they are seemingly different, adding them to the training set would not harm the performance - it will infact improve the performance "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
