{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b1449bb",
   "metadata": {},
   "source": [
    "`` This script designs various strategies to sample training data using the influence function scores ``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5813904",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "013d5286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import torch\n",
    "\n",
    "from utils import load_pickle, pickle_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dda42a",
   "metadata": {},
   "source": [
    "Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87953f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the percentage of samples that we will be using for training\n",
    "ratio_list = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.75, 0.80, 0.85, 0.90]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc493942",
   "metadata": {},
   "source": [
    "Consolidate all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a1b3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 28 checkpoints for analysis\n"
     ]
    }
   ],
   "source": [
    "main_results_folder = \"../../FP_prediction\"\n",
    "all_folders = [] \n",
    "\n",
    "for model in os.listdir(main_results_folder):\n",
    "\n",
    "    main_folder = os.path.join(main_results_folder, model)\n",
    "    for dataset in os.listdir(os.path.join(main_folder, \"best_models\")):\n",
    "\n",
    "        if \"sieved\" in dataset: continue \n",
    "        if \"sampled_random\" in dataset: continue \n",
    "        dataset_folder = os.path.join(main_folder, \"best_models\", dataset)\n",
    "        for checkpoint in os.listdir(dataset_folder):\n",
    "            if \"EK-FAC_scores.pkl\" in os.listdir(os.path.join(dataset_folder, checkpoint)):\n",
    "                assert \"EK-FAC_self_scores.pkl\" in os.listdir(os.path.join(dataset_folder, checkpoint))\n",
    "                all_folders.append(os.path.join(dataset_folder, checkpoint))\n",
    "\n",
    "print(f\"There are {len(all_folders)} checkpoints for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c20f7d9",
   "metadata": {},
   "source": [
    "`` Strategy 1: Pick the top k most important training datapoints``\n",
    "    \n",
    "    Technically, we need to define a metric of importance\n",
    "\n",
    "Recall the equation is:\n",
    "\n",
    "$$f(\\theta^\\star(\\epsilon)) - f(\\theta^\\star) \\approx -\\nabla_\\theta f(\\theta^\\star)^\\top H^{-1} \\nabla_\\theta \\mathcal{L}(z_m, \\theta^\\star)$$\n",
    "\n",
    "To upweigh the examples, we set $$\\epsilon = \\frac{1}{n}$$\n",
    "\n",
    "Since we want $$(f(\\theta^\\star(\\epsilon)) - f(\\theta^\\star))\\epsilon < 0$$\n",
    "\n",
    "$$\\Rightarrow -\\nabla_\\theta f(\\theta^\\star)^\\top H^{-1} \\nabla_\\theta \\mathcal{L}(z_m, \\theta^\\star) \\, \\epsilon < 0$$\n",
    "\n",
    "Therefore, we need to pick the training samples that can lower the loss the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9338aa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [01:22<00:00,  2.93s/it]\n"
     ]
    }
   ],
   "source": [
    "for IDX in tqdm(range(len(all_folders))):\n",
    "\n",
    "    CHECKPOINT = all_folders[IDX]\n",
    "    sample_ids_folder = os.path.join(CHECKPOINT, \"sample_ids\")\n",
    "    if not os.path.exists(sample_ids_folder): os.makedirs(sample_ids_folder)\n",
    "\n",
    "    IF = load_pickle(os.path.join(CHECKPOINT, \"EK-FAC_scores.pkl\"))[\"all_modules\"].T\n",
    "    train_indices = load_pickle(os.path.join(CHECKPOINT, \"train_ids.pkl\"))\n",
    "\n",
    "    helpful_score = torch.topk(-IF.sum(-1), k = IF.shape[0])\n",
    "    helpful_score_idx_sorted = helpful_score.indices.numpy().tolist()\n",
    "\n",
    "    for ratio in ratio_list:\n",
    "\n",
    "        ratio_int = int(ratio * 100)\n",
    "        n_train = int(round(ratio * IF.shape[0], 0))\n",
    "\n",
    "        selected_train_ids = [train_indices[i] for i in helpful_score_idx_sorted[:n_train]]\n",
    "        output_path = os.path.join(sample_ids_folder, f\"top_k_helpful_{ratio_int}.pkl\")\n",
    "        pickle_data(selected_train_ids, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69343d65",
   "metadata": {},
   "source": [
    "`` Strategy 2: Remove the top k most negative samples ``\n",
    "\n",
    "Recall once again, the equation is:\n",
    "\n",
    "$$f(\\theta^\\star(\\epsilon)) - f(\\theta^\\star) \\approx -\\nabla_\\theta f(\\theta^\\star)^\\top H^{-1} \\nabla_\\theta \\mathcal{L}(z_m, \\theta^\\star)$$\n",
    "\n",
    "To remove the examples, we set $$\\epsilon = -\\frac{1}{n}$$\n",
    "\n",
    "Since we want $$(f(\\theta^\\star(\\epsilon)) - f(\\theta^\\star))\\epsilon < 0$$\n",
    "\n",
    "$$\\Rightarrow \\nabla_\\theta f(\\theta^\\star)^\\top H^{-1} \\nabla_\\theta \\mathcal{L}(z_m, \\theta^\\star) \\, \\epsilon > 0$$\n",
    "\n",
    "Therefore, we need to pick the training samples that can lower the loss the most, when removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae2855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../FP_prediction/baseline_models/best_models/massspecgym/MSG_binned_meta_4096_random now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.65it/s]\n",
      "  4%|▎         | 1/28 [00:02<01:08,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../FP_prediction/baseline_models/best_models/massspecgym/MSG_formula_4096_scaffold_vanilla now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.99it/s]\n",
      "  7%|▋         | 2/28 [00:05<01:05,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../FP_prediction/baseline_models/best_models/massspecgym/MSG_formula_meta_4096_random now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.13it/s]\n",
      " 11%|█         | 3/28 [00:07<00:58,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../FP_prediction/baseline_models/best_models/massspecgym/MSG_MS_meta_4096_random now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.54it/s]\n",
      " 14%|█▍        | 4/28 [00:09<00:56,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../FP_prediction/baseline_models/best_models/massspecgym/MSG_MS_4096_inchikey_vanilla now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.98it/s]\n",
      " 18%|█▊        | 5/28 [00:11<00:53,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../FP_prediction/baseline_models/best_models/massspecgym/MSG_binned_4096_scaffold_vanilla now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.84it/s]\n",
      " 21%|██▏       | 6/28 [00:14<00:51,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../FP_prediction/baseline_models/best_models/massspecgym/MSG_formula_4096_inchikey_vanilla now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.30it/s]\n",
      " 25%|██▌       | 7/28 [00:16<00:50,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../FP_prediction/baseline_models/best_models/massspecgym/MSG_MS_4096_scaffold_vanilla now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.42it/s]\n",
      " 29%|██▊       | 8/28 [00:19<00:48,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../FP_prediction/baseline_models/best_models/massspecgym/MSG_binned_4096_inchikey_vanilla now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.06it/s]\n",
      " 32%|███▏      | 9/28 [00:21<00:45,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../../FP_prediction/baseline_models/best_models/nist2023/NIST2023_MS_meta_4096_inchikey_vanilla now\n"
     ]
    }
   ],
   "source": [
    "for IDX in tqdm(range(len(all_folders))):\n",
    "\n",
    "    CHECKPOINT = all_folders[IDX]\n",
    "    print(f\"Processing {CHECKPOINT} now\")\n",
    "    sample_ids_folder = os.path.join(CHECKPOINT, \"sample_ids\")\n",
    "    if not os.path.exists(sample_ids_folder): os.makedirs(sample_ids_folder)\n",
    "\n",
    "    IF = load_pickle(os.path.join(CHECKPOINT, \"EK-FAC_scores.pkl\"))[\"all_modules\"].T\n",
    "    train_indices = load_pickle(os.path.join(CHECKPOINT, \"train_ids.pkl\"))\n",
    "\n",
    "    harmful_score = torch.topk(IF.sum(-1), k = IF.shape[0])\n",
    "    harmful_score_idx_sorted = harmful_score.indices.numpy().tolist()\n",
    "    removal_ratio_list = [1.0 - r for r in ratio_list]\n",
    "\n",
    "    for ratio in tqdm(removal_ratio_list):\n",
    "\n",
    "        ratio_int = int((1.0 - ratio) * 100)\n",
    "        n_train_to_remove = int(round(ratio * IF.shape[0], 0))\n",
    "        selected_train_ids = list(set(train_indices) - set(harmful_score_idx_sorted[:n_train_to_remove]))\n",
    "        \n",
    "        output_path = os.path.join(sample_ids_folder, f\"remove_top_k_harmful_{ratio_int}.pkl\")\n",
    "        pickle_data(selected_train_ids, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d38708",
   "metadata": {},
   "source": [
    "`` Strategy 3: We pick the top k most diverse ones ``\n",
    "\n",
    "    Note that it's almost impossible to get the true optimal solution for this task given the size of our training data \n",
    "    (the runtime was prohibitively long)\n",
    "    We would prematurely terminate the k-means clustering and get the centroid as the diverse samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d4930",
   "metadata": {},
   "outputs": [],
   "source": [
    "for IDX in tqdm(range(len(all_folders))):\n",
    "\n",
    "    CHECKPOINT = all_folders[IDX]\n",
    "    print(f\"Processing {CHECKPOINT} now\")\n",
    "    sample_ids_folder = os.path.join(CHECKPOINT, \"sample_ids\")\n",
    "    if not os.path.exists(sample_ids_folder): os.makedirs(sample_ids_folder)\n",
    "\n",
    "    IF = load_pickle(os.path.join(CHECKPOINT, \"EK-FAC_scores.pkl\"))[\"all_modules\"].T.numpy()\n",
    "    train_indices = load_pickle(os.path.join(CHECKPOINT, \"train_ids.pkl\"))\n",
    "\n",
    "    for ratio in ratio_list:\n",
    "\n",
    "        ratio_int = int(ratio * 100)\n",
    "        n_train = int(round(ratio * IF.shape[0], 0))        \n",
    "        mbk = MiniBatchKMeans(n_clusters = n_train, batch_size = 1024, max_iter=5) # Let us use a small number to speed up the computation \n",
    "        mbk.fit(IF)\n",
    "\n",
    "        # Get centroids\n",
    "        centroids = mbk.cluster_centers_\n",
    "        selected_indices, _ = pairwise_distances_argmin_min(centroids, IF)\n",
    "        selected_train_ids = [train_indices[i] for i in selected_indices]\n",
    "\n",
    "        output_path = os.path.join(sample_ids_folder, f\"k_means_centroid_{ratio_int}.pkl\")\n",
    "        pickle_data(selected_train_ids, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05fc4d2",
   "metadata": {},
   "source": [
    "`` Strategy 4: Removal of samples using self-influence scores ``\n",
    "\n",
    "    The motivation is that many of these methods rely on the test score to subsample the important training records.\n",
    "    We look at how well we can use self-influence score to determine the sampling strategy\n",
    "\n",
    "    So now, we aim to remove potential misannotations in the data\n",
    "\n",
    "Recall once again, the equation for self influence is:\n",
    "\n",
    "$$f(\\theta^\\star(\\epsilon)) - f(\\theta^\\star) \\approx -\\nabla_\\theta \\mathcal{L}(z_m, \\theta^\\star)^\\top H^{-1} \\nabla_\\theta \\mathcal{L}(z_m, \\theta^\\star)$$\n",
    "\n",
    "To remove the examples, we set $$\\epsilon = -\\frac{1}{n}$$\n",
    "\n",
    "Consider:\n",
    "\n",
    "$$f(\\theta^\\star(\\epsilon)) - f(\\theta^\\star) > 0$$\n",
    "\n",
    "Therefore, it is suggested that the higher the self-IF score, the greater the lost increases when it is removed from the test --> this migh suggest that this is a misannotation where very little other training samples can be used to \"support\" its prediction? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836421ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for IDX in tqdm(range(len(all_folders))):\n",
    "\n",
    "    CHECKPOINT = all_folders[IDX]\n",
    "    print(f\"Processing {CHECKPOINT} now\")\n",
    "    sample_ids_folder = os.path.join(CHECKPOINT, \"sample_ids\")\n",
    "    if not os.path.exists(sample_ids_folder): os.makedirs(sample_ids_folder)\n",
    "\n",
    "    self_IF = load_pickle(os.path.join(CHECKPOINT, \"EK-FAC_self_scores.pkl\"))[\"all_modules\"]\n",
    "    train_indices = load_pickle(os.path.join(CHECKPOINT, \"train_ids.pkl\"))\n",
    "\n",
    "    harmful_score = torch.topk(self_IF, k = self_IF.shape[0])\n",
    "    harmful_score_idx_sorted = harmful_score.indices.numpy().tolist()\n",
    "    removal_ratio_list = [1.0 - r for r in ratio_list]\n",
    "\n",
    "    for ratio in tqdm(removal_ratio_list):\n",
    "\n",
    "        ratio_int = int((1.0 - ratio) * 100)\n",
    "        n_train_to_remove = int(round(ratio * self_IF.shape[0], 0))\n",
    "        selected_train_ids = list(set(train_indices) - set(harmful_score_idx_sorted[:n_train_to_remove]))\n",
    "        \n",
    "        output_path = os.path.join(sample_ids_folder, f\"remove_top_k_self_{ratio_int}.pkl\")\n",
    "        pickle_data(selected_train_ids, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d084d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
