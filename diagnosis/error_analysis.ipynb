{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from utils import load_pickle, load_json\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation(results, method1, method2):\n",
    "\n",
    "    loss_method1, loss_method2 = [],[]\n",
    "    rank_method1, rank_method2 = [],[]\n",
    "\n",
    "    for _, v in results.items(): \n",
    "\n",
    "        if method1 in v and method2 in v:\n",
    "            loss_method1.append(v[method1][0])\n",
    "            loss_method2.append(v[method2][0])\n",
    "            rank_method1.append(v[method1][1])\n",
    "            rank_method2.append(v[method2][1])\n",
    "\n",
    "    rank_correlation = round(float(stats.spearmanr(rank_method1, rank_method2).statistic), 3)\n",
    "    linear_correlation = round(float(stats.pearsonr(loss_method1, loss_method2).statistic), 3)\n",
    "\n",
    "    return rank_correlation, linear_correlation, len(loss_method1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get samples that appear across all splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nist2023 2926 ['296987.pkl', '7072.pkl', '343565.pkl']\n",
      "nist2020 3052 ['1629975.pkl', '3172409.pkl', '3033903.pkl']\n",
      "massspecgym 387 ['MassSpecGymID0027651.pkl', 'MassSpecGymID0208724.pkl', 'MassSpecGymID0226518.pkl']\n",
      "canopus 65 ['8196.pkl', '1666.pkl', '11457.pkl']\n"
     ]
    }
   ],
   "source": [
    "splits_folder = \"/data/rbg/users/klingmin/projects/MS_processing/data_splits\"\n",
    "test_ids = {}\n",
    "\n",
    "for dataset in os.listdir(splits_folder):\n",
    "    \n",
    "    test_ids[dataset] = {}\n",
    "    all_ids = None\n",
    "\n",
    "    for splits in os.listdir(os.path.join(splits_folder, dataset, \"splits\")):\n",
    "        \n",
    "        if \"CF\" in splits: continue\n",
    "\n",
    "        current_ids = load_json(os.path.join(splits_folder, dataset, \"splits\", splits))[\"test\"]\n",
    "\n",
    "        if all_ids == None: all_ids = set(current_ids)\n",
    "        all_ids = all_ids.intersection(current_ids)\n",
    "\n",
    "    test_ids[dataset] = all_ids\n",
    "    print(dataset, len(all_ids), list(all_ids)[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = \"/data/rbg/users/klingmin/projects/ML_MS_analysis/FP_prediction/baseline_models/models_cached/morgan4_4096\"\n",
    "mist_results_folder = \"/data/rbg/users/klingmin/projects/ML_MS_analysis/FP_prediction/mist/models_cached/morgan4_4096\"\n",
    "\n",
    "all_results = {} \n",
    "\n",
    "for folder in [results_folder, mist_results_folder]:\n",
    "\n",
    "    for dataset in os.listdir(folder):\n",
    "\n",
    "        dataset_folder = os.path.join(folder, dataset)\n",
    "\n",
    "        if dataset not in all_results: all_results[dataset] = {} \n",
    "\n",
    "        for f in os.listdir(dataset_folder):\n",
    "\n",
    "            test_filepath = os.path.join(dataset_folder, f, \"test_results.pkl\")\n",
    "            test_results = load_pickle(test_filepath)\n",
    "            test_scores = [v[\"loss\"] for _, v in test_results.items()]\n",
    "            test_scores = sorted(test_scores, reverse = True)\n",
    "\n",
    "            # Add to all results\n",
    "            for k, v in test_results.items():\n",
    "                if torch.is_tensor(k): k = k.item()\n",
    "\n",
    "                if k not in all_results[dataset]: all_results[dataset][k] = {}\n",
    "                all_results[dataset][k][f] = (v[\"loss\"], test_scores.index(v[\"loss\"]) / len(test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze MSG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSG_test_results_sieved = {}\n",
    "\n",
    "for dataset, v in all_results.items():\n",
    "    if dataset != \"massspecgym\": continue \n",
    "\n",
    "    for k, scores in v.items():\n",
    "        if f\"{k}.pkl\" in test_ids[dataset]: \n",
    "            MSG_test_results_sieved[k] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because sorted = True ==> descending order ==> smaller the rank, more difficult the example\n",
    "THRESHOLD = 0.2\n",
    "kept_set = {} \n",
    "\n",
    "for model in [\"binned\", \"mist\", \"MS\"]:\n",
    "\n",
    "    id_list = [] \n",
    "\n",
    "    for k, s_pair in MSG_test_results_sieved.items():\n",
    "\n",
    "        sieved_s_pair = [p[1] > THRESHOLD for _, p in s_pair.items() if model in _]\n",
    "        if True in sieved_s_pair: continue \n",
    "        id_list.append(k)\n",
    "    \n",
    "    kept_set[model] = id_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kept_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m kept_set\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kept_set' is not defined"
     ]
    }
   ],
   "source": [
    "kept_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS_4096_random formula_4096_inchikey_vanilla 0.521 0.521 371\n",
      "MS_4096_random binned_4096_inchikey_vanilla 0.536 0.527 424\n",
      "MS_4096_random MS_4096_inchikey_vanilla 0.473 0.496 424\n",
      "MS_4096_random binned_4096_random 0.881 0.893 2744\n",
      "MS_4096_random formula_4096_random 0.797 0.807 394\n",
      "MS_4096_random binned_4096_scaffold_vanilla 0.452 0.447 415\n",
      "MS_4096_random formula_4096_scaffold_vanilla 0.47 0.394 365\n",
      "MS_4096_random MS_4096_scaffold_vanilla 0.364 0.36 415\n",
      "formula_4096_inchikey_vanilla binned_4096_inchikey_vanilla 0.828 0.833 329\n",
      "formula_4096_inchikey_vanilla MS_4096_inchikey_vanilla 0.853 0.848 329\n",
      "formula_4096_inchikey_vanilla binned_4096_random 0.467 0.47 371\n",
      "formula_4096_inchikey_vanilla formula_4096_random 0.45 0.583 360\n",
      "formula_4096_inchikey_vanilla binned_4096_scaffold_vanilla 0.633 0.65 421\n",
      "formula_4096_inchikey_vanilla MS_4096_scaffold_vanilla 0.734 0.71 421\n",
      "binned_4096_inchikey_vanilla MS_4096_inchikey_vanilla 0.858 0.884 2690\n",
      "binned_4096_inchikey_vanilla binned_4096_random 0.475 0.452 424\n",
      "binned_4096_inchikey_vanilla formula_4096_random 0.652 0.665 341\n",
      "binned_4096_inchikey_vanilla binned_4096_scaffold_vanilla 0.813 0.779 392\n",
      "binned_4096_inchikey_vanilla formula_4096_scaffold_vanilla 0.68 0.601 391\n",
      "binned_4096_inchikey_vanilla MS_4096_scaffold_vanilla 0.711 0.69 392\n",
      "MS_4096_inchikey_vanilla binned_4096_random 0.409 0.414 424\n",
      "MS_4096_inchikey_vanilla formula_4096_random 0.582 0.61 341\n",
      "MS_4096_inchikey_vanilla binned_4096_scaffold_vanilla 0.752 0.768 392\n",
      "MS_4096_inchikey_vanilla formula_4096_scaffold_vanilla 0.678 0.641 391\n",
      "MS_4096_inchikey_vanilla MS_4096_scaffold_vanilla 0.786 0.785 392\n",
      "binned_4096_random formula_4096_random 0.809 0.793 394\n",
      "binned_4096_random binned_4096_scaffold_vanilla 0.416 0.43 415\n",
      "binned_4096_random formula_4096_scaffold_vanilla 0.433 0.367 365\n",
      "binned_4096_random MS_4096_scaffold_vanilla 0.299 0.298 415\n",
      "formula_4096_random binned_4096_scaffold_vanilla 0.633 0.577 360\n",
      "formula_4096_random formula_4096_scaffold_vanilla 0.468 0.416 351\n",
      "formula_4096_random MS_4096_scaffold_vanilla 0.454 0.415 360\n",
      "binned_4096_scaffold_vanilla MS_4096_scaffold_vanilla 0.742 0.757 2689\n"
     ]
    }
   ],
   "source": [
    "for m1, m2 in itertools.combinations(all_methods, 2):\n",
    "\n",
    "    spearman, pearson, support = get_correlation(all_results[\"canopus\"], m1, m2)\n",
    "    m1 = \"_\".join(m1.split(\"_\")[1:])\n",
    "    m2 = \"_\".join(m2.split(\"_\")[1:])\n",
    "\n",
    "    if support < 300: continue\n",
    "\n",
    "    print(m1, m2, pearson, spearman, support)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
