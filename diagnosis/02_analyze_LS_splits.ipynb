{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe2088cd",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcbe4d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "from utils import load_pickle, pickle_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cd7bde",
   "metadata": {},
   "source": [
    "Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3dc7b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/data/rbg/users/klingmin/projects/MS_processing/data/\"\n",
    "results_folder = \"/data/rbg/users/klingmin/projects/ML_MS_analysis/FP_prediction/mist/best_ls_results\"\n",
    "analysis_folder = \"./cache/ls_plots\"\n",
    "if not os.path.exists(analysis_folder): os.makedirs(analysis_folder)\n",
    "\n",
    "dataset_mapping = {\"canopus\": \"Canopus\", \n",
    "                   \"massspecgym\": \"MassSpecGym\",\n",
    "                   \"nist2023\": \"NIST2023\"}\n",
    "\n",
    "model_mapping = {\"binned\": \"Binned + MLP\",\n",
    "                 \"MS\" : \"MS + Transformer\",\n",
    "                 \"formula\": \"Formula + Transformer\",\n",
    "                 \"MIST\": \"MIST\"}\n",
    "\n",
    "splits_mapping = {\"scaffold_vanilla\": \"scaffold split\",\n",
    "                  \"inchikey_vanilla\": \"inchikey split\",\n",
    "                  \"random\": \"random split\"}\n",
    "\n",
    "NIST_instrument_mapping = {\"Agilent QTOF 6530\": \"Agilent QTOF \\n 6530\",\n",
    "                           \"Thermo Finnigan Elite Orbitrap\": \"Thermo \\n Finnigan \\n Elite Orbitrap\",\n",
    "                           \"Orbitrap Fusion Lumos\": \"Orbitrap \\n Fusion Lumos\",\n",
    "                           \"Thermo Finnigan Velos Orbitrap\": \"Thermo \\n Finnigan \\n Velos Orbitrap\"}\n",
    "\n",
    "train_color_code, test_color_code = \"#92898A\", \"#C95D63\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449d2ca4",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac2c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_ratio(train_data, test_data):\n",
    "\n",
    "    ratio = round(len(test_data) / (len(train_data) + len(test_data)) * 100, 3)\n",
    "\n",
    "    return ratio\n",
    "\n",
    "def get_percentage_mol_overlap(train_data, test_data):\n",
    "\n",
    "    train_mols = set([r[\"inchikey_original\"][:14] for r in train_data])\n",
    "    test_mols = set([r[\"inchikey_original\"][:14] for r in test_data])\n",
    "\n",
    "    percent_overlap = round(len(train_mols.intersection(test_mols)) / len(test_data) * 100, 3)\n",
    "\n",
    "    return percent_overlap\n",
    "\n",
    "def get_oov_rate(train_data, test_data):\n",
    " \n",
    "    train_formula = set([p[\"comment\"][\"f_pred\"] for f in train_data for p in f[\"peaks\"] if p[\"comment\"][\"f_pred\"] != \"\"])\n",
    "    test_formula = set([p[\"comment\"][\"f_pred\"] for f in test_data for p in f[\"peaks\"] if p[\"comment\"][\"f_pred\"] != \"\"])\n",
    "\n",
    "    oov_rate = len(test_formula - train_formula) / len(test_formula) * 100\n",
    "    \n",
    "    return oov_rate\n",
    "\n",
    "def get_instrument_breakdown(train_data, test_data, key = \"instrument_type\"):\n",
    "        \n",
    "    train_instruments = collections.Counter([r[key] for r in train_data])\n",
    "    test_instruments = collections.Counter([r[key] for r in test_data])\n",
    "\n",
    "    unique_instruments = set(list(train_instruments.keys()) + list(test_instruments.keys()))\n",
    "\n",
    "    train_instrument_counts = [train_instruments[i] if i in train_instruments else 0 for i in unique_instruments]\n",
    "    test_instrument_counts = [test_instruments[i] if i in test_instruments else 0 for i in unique_instruments]\n",
    "\n",
    "    return (train_instruments,train_instrument_counts), (test_instruments, test_instrument_counts), unique_instruments\n",
    "\n",
    "def get_adduct_breakdown(train_data, test_data):\n",
    "                \n",
    "    train_adducts = collections.Counter([r[\"precursor_type\"] for r in train_data])\n",
    "    test_adducts = collections.Counter([r[\"precursor_type\"] for r in test_data])\n",
    "\n",
    "    unique_adducts = set(list(train_adducts.keys()) + list(test_adducts.keys()))\n",
    "\n",
    "    train_adduct_counts = [train_adducts[i] if i in train_adducts else 0 for i in unique_adducts]\n",
    "    test_adduct_counts = [test_adducts[i] if i in test_adducts else 0 for i in unique_adducts]\n",
    "\n",
    "    return (train_adducts, train_adduct_counts), (test_adducts, test_adduct_counts), unique_adducts\n",
    "\n",
    "def get_energy_breakdown(train_data, test_data):\n",
    "\n",
    "    train_energies = collections.Counter([r[\"collision_energy\"] for r in train_data])\n",
    "    test_energies = collections.Counter([r[\"collision_energy\"] for r in test_data])\n",
    "\n",
    "    energy_bins = [\"-\", \"0-20\", \"20-40\", \"40-60\", \"60-80\", \"80-100\", \"100-120\", \"120-150\", \">150\"]\n",
    "    train_energies_binned = {\"-\": 0, \"0-20\": 0, \"20-40\": 0, \"40-60\": 0, \"60-80\": 0, \"80-100\": 0, \"100-120\":0, \"120-150\": 0, \">150\": 0}\n",
    "    test_energies_binned = {\"-\": 0, \"0-20\": 0, \"20-40\": 0, \"40-60\": 0, \"60-80\": 0, \"80-100\": 0, \"100-120\":0, \"120-150\": 0, \">150\": 0}\n",
    "\n",
    "    for e,c in train_energies.items():\n",
    "\n",
    "        if e == \"-\": train_energies_binned[\"-\"] += c \n",
    "        elif e is None: train_energies_binned[\"-\"] += c\n",
    "        elif e < 20: train_energies_binned[\"0-20\"] += c \n",
    "        elif e < 40: train_energies_binned[\"20-40\"] += c \n",
    "        elif e < 60: train_energies_binned[\"40-60\"] += c \n",
    "        elif e < 80: train_energies_binned[\"60-80\"] += c \n",
    "        elif e < 100: train_energies_binned[\"80-100\"] += c \n",
    "        elif e < 120: train_energies_binned[\"100-120\"] += c \n",
    "        elif e < 150: train_energies_binned[\"120-150\"] += c \n",
    "        else: train_energies_binned[\">150\"] += c \n",
    "\n",
    "    for e,c in test_energies.items():\n",
    "\n",
    "        if e == \"-\": test_energies_binned[\"-\"] += c \n",
    "        elif e is None: test_energies_binned[\"-\"] += c\n",
    "        elif e < 20: test_energies_binned[\"0-20\"] += c \n",
    "        elif e < 40: test_energies_binned[\"20-40\"] += c \n",
    "        elif e < 60: test_energies_binned[\"40-60\"] += c \n",
    "        elif e < 80: test_energies_binned[\"60-80\"] += c \n",
    "        elif e < 100: test_energies_binned[\"80-100\"] += c \n",
    "        elif e < 120: test_energies_binned[\"100-120\"] += c \n",
    "        elif e < 150: test_energies_binned[\"120-150\"] += c \n",
    "        else: test_energies_binned[\">150\"] += c \n",
    "\n",
    "    train_binned_energy_counts = [train_energies_binned[i] for i in test_energies_binned.keys()]\n",
    "    test_binned_energy_counts = [test_energies_binned[i] for i in test_energies_binned.keys()]\n",
    "\n",
    "    return (train_energies_binned, train_binned_energy_counts), (test_energies_binned, test_binned_energy_counts), energy_bins\n",
    "\n",
    "def get_molecule_class(train_data, test_data):\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83ed3bb",
   "metadata": {},
   "source": [
    "Iterate through the various LS results to obtain the charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91ac8200",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [\"canopus\", \"massspecgym\", \"nist2023\"]:\n",
    "\n",
    "    current_data_folder = os.path.join(data_folder, dataset, \"frags_preds\")\n",
    "\n",
    "    ls_results_folder = [os.path.join(results_folder, f) for f in os.listdir(results_folder) if dataset in f and \"sieved\" not in f]\n",
    "    assert len(ls_results_folder) == 1\n",
    "    ls_results_folder = ls_results_folder[0]\n",
    "\n",
    "    stats_path = os.path.join(analysis_folder, f\"{dataset}_ls_stats.pkl\")\n",
    "    if os.path.exists(stats_path): continue\n",
    "\n",
    "    split = load_pickle(os.path.join(ls_results_folder, \"best_split.pkl\"))\n",
    "    data_ids = load_pickle(os.path.join(ls_results_folder, \"data_ids.pkl\"))\n",
    "\n",
    "    # Get the train and test data now\n",
    "    train_ids = [data_ids[i] for i in split[\"train_indices\"]]\n",
    "    test_ids = [data_ids[i] for i in split[\"test_indices\"]]\n",
    "\n",
    "    train_data = [load_pickle(os.path.join(current_data_folder, f\"{i}.pkl\")) for i in train_ids]\n",
    "    test_data = [load_pickle(os.path.join(current_data_folder, f\"{i}.pkl\")) for i in test_ids]\n",
    "\n",
    "    # # Get the train test ratio\n",
    "    # if dataset == \"nist2023\": instrument_key = \"instrument\"\n",
    "    # else: instrument_key = \"instrument_type\"\n",
    "    # stats = {} \n",
    "    # stats[\"train_test_ratio\"] = get_train_test_ratio(train_data, test_data)\n",
    "    # stats[\"percent_overlap\"] = get_percentage_mol_overlap(train_data, test_data)\n",
    "    # stats[\"oov_rate\"] = get_oov_rate(train_data, test_data) \n",
    "    # stats[\"instrument_breakdown\"]  = get_instrument_breakdown(train_data, test_data, key = instrument_key)\n",
    "    # stats[\"adduct_breakdown\"] = get_adduct_breakdown(train_data, test_data)\n",
    "    # stats[\"energy_breakdown\"] = get_energy_breakdown(train_data, test_data)\n",
    "\n",
    "    # # Add to the data \n",
    "    # pickle_data(stats, stats_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5f4448",
   "metadata": {},
   "source": [
    "Iterate through the various LS results to obtain OOV rate for sieved results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09f30706",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [\"massspecgym\", \"nist2023\"]:\n",
    "\n",
    "    current_data_folder = os.path.join(data_folder, dataset, \"frags_preds\")\n",
    "\n",
    "    ls_results_folder = [os.path.join(results_folder, f) for f in os.listdir(results_folder) if dataset in f and \"sieved\" in f]\n",
    "    assert len(ls_results_folder) == 1\n",
    "    ls_results_folder = ls_results_folder[0]\n",
    "\n",
    "    stats_path = os.path.join(analysis_folder, f\"{dataset}_sieved_ls_stats.pkl\")\n",
    "    if os.path.exists(stats_path): continue\n",
    "\n",
    "    split = load_pickle(os.path.join(ls_results_folder, \"best_split.pkl\"))\n",
    "    data_ids = load_pickle(os.path.join(ls_results_folder, \"data_ids.pkl\"))\n",
    "\n",
    "    # Get the train and test data now\n",
    "    train_ids = [data_ids[i] for i in split[\"train_indices\"]]\n",
    "    test_ids = [data_ids[i] for i in split[\"test_indices\"]]\n",
    "\n",
    "    train_data = [load_pickle(os.path.join(current_data_folder, f\"{i}.pkl\")) for i in train_ids]\n",
    "    test_data = [load_pickle(os.path.join(current_data_folder, f\"{i}.pkl\")) for i in test_ids]\n",
    "\n",
    "    # Get the stats\n",
    "    stats = {} \n",
    "    stats[\"train_test_ratio\"] = get_train_test_ratio(train_data, test_data)\n",
    "    stats[\"percent_overlap\"] = get_percentage_mol_overlap(train_data, test_data)\n",
    "    stats[\"oov_rate\"] = get_oov_rate(train_data, test_data) \n",
    "\n",
    "    # Add to the data \n",
    "    pickle_data(stats, stats_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acabc1dc",
   "metadata": {},
   "source": [
    "``Let us plot the histograms and compute the chi square test scores``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f43eca",
   "metadata": {},
   "source": [
    "1. Plot the instrument split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a703b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get the instrument split\n",
    "for dataset in [\"canopus\", \"massspecgym\", \"nist2023\"]:\n",
    "\n",
    "    instrument_output_path = os.path.join(analysis_folder, f\"{dataset}_instrument_split.jpg\")\n",
    "    stats = load_pickle(os.path.join(analysis_folder, f\"{dataset}_ls_stats.pkl\"))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    bar_width = 0.23\n",
    "\n",
    "    (train_instruments_breakdown, _), (test_instruments_breakdown, _), unique_instruments = stats[\"instrument_breakdown\"]\n",
    "    unique_instruments = list(set(list(train_instruments_breakdown.keys()) + list(test_instruments_breakdown.keys())))\n",
    "    train_instruments_counts = [train_instruments_breakdown[u] for u in unique_instruments]\n",
    "    test_instruments_counts = [test_instruments_breakdown[u] for u in unique_instruments]\n",
    "\n",
    "    _, p_instrument, _, _ = chi2_contingency(np.array([train_instruments_counts, test_instruments_counts]))\n",
    "\n",
    "    train_bars = np.arange(len(unique_instruments))\n",
    "    test_bars = [x + bar_width + 0.01 for x in train_bars]\n",
    "    n_train, n_test = sum(train_instruments_counts), sum(test_instruments_counts)\n",
    "\n",
    "    unique_instruments = [str(u) for u in unique_instruments]\n",
    "    \n",
    "    if dataset == \"massspecgym\":\n",
    "\n",
    "        idx = unique_instruments.index(\"None\")\n",
    "        train_instruments_counts = [c for i, c in enumerate(train_instruments_counts) if i != idx]\n",
    "        test_instruments_counts = [c for i, c in enumerate(test_instruments_counts) if i != idx]\n",
    "        unique_instruments = [u for u in unique_instruments if u != \"None\"]\n",
    "\n",
    "    train_bars = np.arange(len(unique_instruments))\n",
    "    test_bars = [x + bar_width + 0.01 for x in train_bars]\n",
    "\n",
    "    plt.bar(train_bars, [x / n_train for x in train_instruments_counts], width = bar_width, label ='train', color = train_color_code) \n",
    "    plt.bar(test_bars, [x / n_test for x in test_instruments_counts], width = bar_width, label ='test', color =  test_color_code) \n",
    "\n",
    "    plt.ylabel('Percentage of samples (%)', fontsize = 12)\n",
    "    \n",
    "    if dataset == \"massspecgym\": unique_instruments = [u for u in unique_instruments if u != \"None\"]\n",
    "    if dataset == \"canopus\": unique_instruments = [u.replace(\"(LCMS)\", \"\").strip() for u in unique_instruments]\n",
    "    if dataset == \"nist2023\": unique_instruments = [NIST_instrument_mapping[u] for u in unique_instruments]\n",
    "    plt.xticks([r + bar_width - 0.1 for r in range(len(unique_instruments))], unique_instruments, rotation = 90)\n",
    "\n",
    "    plt.legend()\n",
    "    dataset_ = dataset_mapping[dataset]\n",
    "    plt.title(f\"Breakdown of measurement instrument ({dataset_}) - p-value: {p_instrument: .2e}\")\n",
    "    plt.savefig(instrument_output_path, bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c016eb",
   "metadata": {},
   "source": [
    "2. Plot the adduct split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24be873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Get the adduct split \n",
    "for dataset in [\"canopus\", \"massspecgym\", \"nist2023\"]:\n",
    "\n",
    "    adduct_output_path = os.path.join(analysis_folder, f\"{dataset}_adduct_split.jpg\")\n",
    "    stats = load_pickle(os.path.join(analysis_folder, f\"{dataset}_ls_stats.pkl\"))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    bar_width = 0.23\n",
    "\n",
    "    (train_adducts_breakdown, _), (test_adducts_breakdown, _), unique_adducts = stats[\"adduct_breakdown\"]\n",
    "\n",
    "    unique_adducts = list(set(list(train_adducts_breakdown.keys()) + list(test_adducts_breakdown.keys())))\n",
    "    train_adducts_counts = [train_adducts_breakdown[u] for u in unique_adducts]\n",
    "    test_adducts_counts = [test_adducts_breakdown[u] for u in unique_adducts]\n",
    "\n",
    "    n_train, n_test = sum(train_adducts_counts), sum(test_adducts_counts)\n",
    "    _, p_adduct, _, _ = chi2_contingency(np.array([train_adducts_counts, test_adducts_counts]))\n",
    "    \n",
    "    train_bars = np.arange(len(unique_adducts))\n",
    "    test_bars = [x + bar_width + 0.01 for x in train_bars]\n",
    "\n",
    "    plt.bar(train_bars, [x / n_train for x in train_adducts_counts], width = bar_width, label ='train', color = train_color_code) \n",
    "    plt.bar(test_bars, [x / n_test for x in test_adducts_counts], width = bar_width, label ='test', color  = test_color_code) \n",
    "\n",
    "    plt.ylabel('Percentage of samples (%)', fontsize = 12)\n",
    "    plt.xticks([r + bar_width - 0.1 for r in range(len(unique_adducts))], unique_adducts, rotation = 90)\n",
    "\n",
    "    plt.legend()\n",
    "    dataset_ = dataset_mapping[dataset]\n",
    "    plt.title(f\"Breakdown of adduct ({dataset_}) - p-value: {p_adduct: .2e}\")\n",
    "    plt.savefig(adduct_output_path, bbox_inches = \"tight\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d06009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Energy split \n",
    "\n",
    "for dataset in [\"canopus\", \"massspecgym\", \"nist2023\"]:\n",
    "\n",
    "    energy_output_path = os.path.join(analysis_folder, f\"{dataset}_energy_split.jpg\")\n",
    "    stats = load_pickle(os.path.join(analysis_folder, f\"{dataset}_ls_stats.pkl\"))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    bar_width = 0.23\n",
    "\n",
    "    (train_binned_energy_breakdown,_), (test_binned_energy_breakdown, _), _ = stats[\"energy_breakdown\"]\n",
    "    energy_bins = list(train_binned_energy_breakdown) \n",
    "\n",
    "    train_binned_energy_counts = [train_binned_energy_breakdown[e] for e in energy_bins]\n",
    "    test_binned_energy_counts = [test_binned_energy_breakdown[e] for e in energy_bins]\n",
    "    \n",
    "    n_train, n_test = sum(train_binned_energy_counts), sum(test_binned_energy_counts)\n",
    "\n",
    "    if dataset == \"massspecgym\":\n",
    "\n",
    "        train_binned_energy_counts = train_binned_energy_counts[1:]\n",
    "        test_binned_energy_counts = test_binned_energy_counts[1:]\n",
    "        energy_bins = energy_bins[1:]\n",
    "\n",
    "    _, p_energy, _, _ = chi2_contingency(np.array([train_binned_energy_counts, test_binned_energy_counts]))\n",
    "\n",
    "    train_bars = np.arange(len(train_binned_energy_counts))\n",
    "    test_bars = [x + bar_width for x in train_bars]\n",
    "\n",
    "    plt.bar(train_bars, [x / n_train for x in train_binned_energy_counts], width = bar_width, label ='train', color = train_color_code) \n",
    "    plt.bar(test_bars, [x / n_test for x in test_binned_energy_counts], width = bar_width, label ='test', color = test_color_code) \n",
    "\n",
    "    plt.ylabel('Percentage of samples (%)', fontsize = 12)\n",
    "    plt.xticks([r + bar_width - 0.05 for r in range(len(energy_bins))], energy_bins)\n",
    "\n",
    "    plt.legend()\n",
    "    dataset_ = dataset_mapping[dataset]\n",
    "    plt.title(f\"Breakdown of energy levels ({dataset_}) - p-value: {p_energy:.2e}\")\n",
    "    plt.savefig(energy_output_path, bbox_inches = \"tight\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166cae96",
   "metadata": {},
   "source": [
    "Print the other statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb1645e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canopus 29.698 2.884 38.128515106784505\n",
      "\n",
      "massspecgym 17.501 10.884 36.797562626946515\n",
      "\n",
      "nist2023 4.881 9.513 9.520076160609285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for dataset in [\"canopus\", \"massspecgym\", \"nist2023\"]:\n",
    "\n",
    "    stats = load_pickle(os.path.join(analysis_folder, f\"{dataset}_ls_stats.pkl\"))\n",
    "\n",
    "    train_test_ratio = stats[\"train_test_ratio\"]\n",
    "    percent_overlap = stats[\"percent_overlap\"]\n",
    "    oov_rate = stats[\"oov_rate\"]\n",
    "    print(dataset, train_test_ratio, percent_overlap, oov_rate)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c7db125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "massspecgym 38.361 4.805 51.54240301160724\n",
      "\n",
      "nist2023 15.103 13.346 22.29890643985419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for dataset in [\"massspecgym\", \"nist2023\"]:\n",
    "\n",
    "    stats = load_pickle(os.path.join(analysis_folder, f\"{dataset}_sieved_ls_stats.pkl\"))\n",
    "\n",
    "    train_test_ratio = stats[\"train_test_ratio\"]\n",
    "    percent_overlap = stats[\"percent_overlap\"]\n",
    "    oov_rate = stats[\"oov_rate\"]\n",
    "    print(dataset, train_test_ratio, percent_overlap, oov_rate)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2191b3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
