{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56fd84f7",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9412fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "import numpy as np \n",
    "from tqdm import tqdm \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from utils import load_pickle, load_json, pickle_data, compute_MS_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418f84fa",
   "metadata": {},
   "source": [
    "Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc4433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_folder = \"./cache/baselines\"\n",
    "data_folder = \"/data/rbg/users/klingmin/projects/MS_processing/data/\"\n",
    "splits_folder = \"/data/rbg/users/klingmin/projects/MS_processing/data_splits/\"\n",
    "batched_data_folder = [os.path.join(baseline_folder, f) for f in os.listdir(baseline_folder) if \"nist2023\" in f and os.path.isdir(os.path.join(baseline_folder, f))]\n",
    "\n",
    "datasets = [\"canopus\", \"massspecgym\"]\n",
    "splits = [\"scaffold_vanilla\", \"inchikey_vanilla\", \"random\", \"LS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634299a9",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e057360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_bits(string): \n",
    "\n",
    "    bits = np.array([int(c) for c in string])\n",
    "\n",
    "    return bits\n",
    "\n",
    "@torch.no_grad()\n",
    "def batch_jaccard_index(FP_pred, FP):\n",
    "\n",
    "    # Intersection = bitwise AND\n",
    "    intersection = np.logical_and(FP, FP_pred).sum(axis=1)\n",
    "\n",
    "    # Union = bitwise OR\n",
    "    union = np.logical_or(FP, FP_pred).sum(axis=1)\n",
    "\n",
    "    # Avoid division-by-zero by adding a small epsilon\n",
    "    jaccard_scores = intersection / (union + 1e-9)\n",
    "\n",
    "    return jaccard_scores\n",
    "\n",
    "def bin_MS(peaks, bin_resolution = 0.25, max_da = 2000):\n",
    "\n",
    "    mz = [p[\"mz\"] for p in peaks]\n",
    "    intensities = [p[\"intensity\"] for p in peaks]\n",
    "    \n",
    "    n_bins = int(math.ceil(max_da / bin_resolution))\n",
    "\n",
    "    mz_binned = [0 for _ in range(n_bins)]\n",
    "    for m, i in zip(mz, intensities):\n",
    "        \n",
    "        m = math.floor(m / bin_resolution)\n",
    "        if m >= n_bins: continue \n",
    "        mz_binned[m] += i\n",
    "\n",
    "    return mz_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e01749a",
   "metadata": {},
   "source": [
    "Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe9b289",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_info = {} \n",
    "\n",
    "canopus = load_pickle(os.path.join(data_folder, \"canopus\", \"canopus_w_mol_info_w_frag_CF_preds.pkl\"))\n",
    "canopus = {str(r[\"id_\"]) : r for r in canopus}\n",
    "print(\"Done loading canopus\")\n",
    "\n",
    "massspecgym = load_pickle(os.path.join(data_folder, \"massspecgym\", \"massspecgym_w_mol_info_w_frag_CF_preds.pkl\"))\n",
    "massspecgym = {str(r[\"id_\"]) : r for r in massspecgym}\n",
    "print(\"Done loading MSG\")\n",
    "\n",
    "dataset_info[\"canopus\"] = canopus\n",
    "dataset_info[\"massspecgym\"] = massspecgym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe6eb6e",
   "metadata": {},
   "source": [
    "Iterate through the files within each folder to get the nearest neighbour for each test (only for NIST2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da5134a",
   "metadata": {},
   "source": [
    "For the full training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949cdfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in batched_data_folder:\n",
    "\n",
    "    output_path = folder.replace(\"_batched\", \"\") + \".pkl\"\n",
    "    if os.path.exists(output_path): continue \n",
    "\n",
    "    files = [os.path.join(folder, f) for f in os.listdir(folder)]\n",
    "\n",
    "    best_scores = None\n",
    "\n",
    "    print(f\"Processing: {folder} now\")\n",
    "    \n",
    "    for f in files:\n",
    "\n",
    "        test_ids, train_id, sim = load_pickle(f)\n",
    "        if best_scores is None: \n",
    "            best_scores = {test_ids[i]: {\"train\": train_id[i], \"sim\": sim[i]} for i in range(len(test_ids))}\n",
    "        \n",
    "        else:\n",
    "\n",
    "            for i, test_id in enumerate(test_ids):\n",
    "                current_best_sim = best_scores[test_id][\"sim\"]\n",
    "                if current_best_sim < sim[i]:\n",
    "                    best_scores[test_id] = {\"train\": train_id[i], \"sim\": sim[i]}\n",
    "\n",
    "    pickle_data(best_scores, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d7290",
   "metadata": {},
   "source": [
    "`` Get the jaccard score now ``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b5f4f",
   "metadata": {},
   "source": [
    "`` 1. Across all train, using MS similarity ``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec4de50",
   "metadata": {},
   "source": [
    "`` a. canopus and MSG ``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1 \n",
    "compute = False \n",
    "\n",
    "if compute: \n",
    "\n",
    "    for dataset in datasets: \n",
    "\n",
    "        for split in splits:\n",
    "            \n",
    "            similarity, test_ids, train_ids = load_pickle(os.path.join(folder, f\"{dataset}_{split}.pkl\"))\n",
    "\n",
    "            # Get the top k \n",
    "            top_train_idx = np.argmax(similarity, axis = 1)\n",
    "\n",
    "            # Get jaccard list \n",
    "            all_jaccard = []\n",
    "\n",
    "            for i, test in enumerate(test_ids):\n",
    "\n",
    "                top_train = str(train_ids[top_train_idx[i]])\n",
    "                test = str(test)\n",
    "\n",
    "                test_FP = string_to_bits(dataset_info[dataset][test][\"FPs\"][\"morgan4_4096\"])\n",
    "                train_FP = string_to_bits(dataset_info[dataset][top_train][\"FPs\"][\"morgan4_4096\"])\n",
    "\n",
    "                test_FP = np.expand_dims(test_FP, axis = 0)\n",
    "                train_FP = np.expand_dims(train_FP, axis = 0)\n",
    "\n",
    "                jaccard = batch_jaccard_index(train_FP, test_FP)\n",
    "                all_jaccard.append(jaccard)\n",
    "\n",
    "            print(dataset, split, np.mean(all_jaccard))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59075537",
   "metadata": {},
   "source": [
    "`` b. NIST2023 ``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57ff841",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute = False \n",
    "\n",
    "if compute:\n",
    "\n",
    "    for splitname in splits:\n",
    "\n",
    "        results = load_pickle(f\"./cache/baselines/nist2023_{splitname}.pkl\")\n",
    "        \n",
    "        # Get jaccard list \n",
    "        all_jaccard = []\n",
    "        \n",
    "        for test_id, rec in tqdm(results.items()): \n",
    "\n",
    "            top_train = rec[\"train\"]\n",
    "\n",
    "\n",
    "            train_FP = string_to_bits(load_pickle(os.path.join(data_folder, \"nist2023\", \"frags_preds\", f\"{top_train}.pkl\"))[\"FPs\"][\"morgan4_4096\"])\n",
    "            test_FP = string_to_bits(load_pickle(os.path.join(data_folder, \"nist2023\", \"frags_preds\", f\"{test_id}.pkl\"))[\"FPs\"][\"morgan4_4096\"])\n",
    "\n",
    "            test_FP = np.expand_dims(test_FP, axis = 0)\n",
    "            train_FP = np.expand_dims(train_FP, axis = 0)\n",
    "\n",
    "            jaccard = batch_jaccard_index(train_FP, test_FP)\n",
    "            all_jaccard.append(jaccard)\n",
    "        \n",
    "        print(splitname, np.mean(all_jaccard))\n",
    "        \n",
    "# scaffold_vanilla 0.181914345591279\n",
    "# inchikey_vanilla 0.22553987089030317\n",
    "# random 0.653309319738518\n",
    "# LS 0.17827926093869034"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc65c72f",
   "metadata": {},
   "source": [
    "`` 2. Across all train, using dreaMS ``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8414b6",
   "metadata": {},
   "source": [
    "`` a. Canopus and MSG``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b202c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1 \n",
    "compute = False \n",
    "\n",
    "if compute: \n",
    "\n",
    "    for dataset in datasets: \n",
    "\n",
    "        if dataset != \"massspecgym\": continue\n",
    "\n",
    "        for split in splits:\n",
    "            \n",
    "            similarity, test_ids, train_ids = load_pickle(os.path.join(baseline_folder, f\"{dataset}_{split}_w_emb.pkl\"))\n",
    "\n",
    "            # Get the top k\n",
    "            top_train_idx = np.argmax(similarity, axis = 1)\n",
    "            \n",
    "            # Get jaccard list \n",
    "            all_jaccard = []\n",
    "\n",
    "            for i, test in enumerate(test_ids):\n",
    "\n",
    "                train_idx = top_train_idx[i]\n",
    "                if train_idx >= len(train_ids): print(i, train_idx)\n",
    "\n",
    "                top_train = str(train_ids[train_idx])\n",
    "                test = str(test)\n",
    "\n",
    "                test_FP = string_to_bits(dataset_info[dataset][test][\"FPs\"][\"morgan4_4096\"])\n",
    "                train_FP = string_to_bits(dataset_info[dataset][top_train][\"FPs\"][\"morgan4_4096\"])\n",
    "\n",
    "                test_FP = np.expand_dims(test_FP, axis = 0)\n",
    "                train_FP = np.expand_dims(train_FP, axis = 0)\n",
    "\n",
    "                jaccard = batch_jaccard_index(train_FP, test_FP)\n",
    "                all_jaccard.append(jaccard)\n",
    "\n",
    "            print(dataset, split, np.mean(all_jaccard))\n",
    "\n",
    "# canopus scaffold_vanilla 0.2612578164438585\n",
    "# canopus inchikey_vanilla 0.3756794990803615\n",
    "# canopus random 0.6902512724412937\n",
    "# canopus LS 0.23034789850227105\n",
    "# massspecgym scaffold_vanilla 0.296826992523911\n",
    "# massspecgym inchikey_vanilla 0.3212731824194335\n",
    "# massspecgym random 0.8947928743650205\n",
    "# massspecgym LS 0.24703036830506597"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad2b872",
   "metadata": {},
   "source": [
    "`` b. NIST2023 ``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute = True\n",
    "\n",
    "if compute:\n",
    "\n",
    "    for splitname in splits:\n",
    "\n",
    "        results = load_pickle(f\"./cache/baselines/nist2023_{splitname}_w_emb.pkl\")\n",
    "        \n",
    "        # Get jaccard list \n",
    "        all_jaccard = []\n",
    "        \n",
    "        for test_id, rec in tqdm(results.items()): \n",
    "\n",
    "            top_train = rec[\"train\"]\n",
    "\n",
    "            train_FP = string_to_bits(load_pickle(os.path.join(data_folder, \"nist2023\", \"frags_preds\", f\"{top_train}.pkl\"))[\"FPs\"][\"morgan4_4096\"])\n",
    "            test_FP = string_to_bits(load_pickle(os.path.join(data_folder, \"nist2023\", \"frags_preds\", f\"{test_id}.pkl\"))[\"FPs\"][\"morgan4_4096\"])\n",
    "\n",
    "            test_FP = np.expand_dims(test_FP, axis = 0)\n",
    "            train_FP = np.expand_dims(train_FP, axis = 0)\n",
    "\n",
    "            jaccard = batch_jaccard_index(train_FP, test_FP)\n",
    "            all_jaccard.append(jaccard)\n",
    "        \n",
    "        print(splitname, np.mean(all_jaccard))\n",
    "\n",
    "# scaffold_vanilla 0.10875046435233811\n",
    "# Inchikey_vanilla 0.12172197379638601\n",
    "# random 0.7942182863047585\n",
    "# LS 0.25098703847393744"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0190024f",
   "metadata": {},
   "source": [
    "`` 3. Identical CF using MS similarity ``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c4b6a7",
   "metadata": {},
   "source": [
    "`` a. Canopus and MSG ``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d1a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1 \n",
    "compute = True \n",
    "\n",
    "if compute:\n",
    "\n",
    "    for dataset in datasets:\n",
    "\n",
    "        for split in splits:\n",
    "            \n",
    "            similarity, test_ids, train_ids = load_pickle(os.path.join(baseline_folder, f\"{dataset}_{split}.pkl\"))\n",
    "\n",
    "            # Get jaccard list \n",
    "            all_jaccard = []\n",
    "\n",
    "            for i, test in enumerate(test_ids):\n",
    "\n",
    "                test_CF  = dataset_info[dataset][test][\"formula\"]\n",
    "\n",
    "                current_similarity = similarity[i, :]\n",
    "                sort_idx = np.argsort(current_similarity)[::-1]\n",
    "                current_similarity = [current_similarity[i] for i in sort_idx]\n",
    "                current_train_ids = [train_ids[i] for i in sort_idx]\n",
    "                current_train_ids = [(idx, t) for idx, t in enumerate(current_train_ids) if \n",
    "                                    dataset_info[dataset][t][\"formula\"] == test_CF]\n",
    "                \n",
    "                if len(current_train_ids) == 0: continue \n",
    "                top_train = current_train_ids[0][1]\n",
    "\n",
    "                test_FP = string_to_bits(dataset_info[dataset][test][\"FPs\"][\"morgan4_4096\"])\n",
    "                train_FP = string_to_bits(dataset_info[dataset][top_train][\"FPs\"][\"morgan4_4096\"])\n",
    "\n",
    "                test_FP = np.expand_dims(test_FP, axis = 0)\n",
    "                train_FP = np.expand_dims(train_FP, axis = 0)\n",
    "                jaccard = batch_jaccard_index(train_FP, test_FP)\n",
    "\n",
    "                all_jaccard.append(jaccard)\n",
    "\n",
    "            print(dataset, split, np.mean(all_jaccard))\n",
    "\n",
    "# canopus scaffold_vanilla 0.2848325413342964\n",
    "# canopus inchikey_vanilla 0.38684986445373354\n",
    "# canopus random 0.824085252277534\n",
    "# canopus LS 0.34640551573294376\n",
    "# massspecgym scaffold_vanilla 0.4549473041238532\n",
    "# massspecgym inchikey_vanilla 0.333642300735451\n",
    "# massspecgym random 0.95552811447368\n",
    "# massspecgym LS 0.5200194596102301"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2df38",
   "metadata": {},
   "source": [
    "`` b. NIST2023 ``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b6ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute = True\n",
    "\n",
    "if compute:\n",
    "\n",
    "    for splitname in splits:\n",
    "\n",
    "        results = load_pickle(f\"./cache/baselines/nist2023_{splitname}_same_CF.pkl\")\n",
    "        \n",
    "        # Get jaccard list \n",
    "        all_jaccard = []\n",
    "        \n",
    "        for test_id, rec in tqdm(results.items()): \n",
    "\n",
    "            top_train = rec[\"train\"]\n",
    "            if top_train == \"-\": continue\n",
    "\n",
    "            train_FP = string_to_bits(load_pickle(os.path.join(data_folder, \"nist2023\", \"frags_preds\", f\"{top_train}.pkl\"))[\"FPs\"][\"morgan4_4096\"])\n",
    "            test_FP = string_to_bits(load_pickle(os.path.join(data_folder, \"nist2023\", \"frags_preds\", f\"{test_id}.pkl\"))[\"FPs\"][\"morgan4_4096\"])\n",
    "\n",
    "            test_FP = np.expand_dims(test_FP, axis = 0)\n",
    "            train_FP = np.expand_dims(train_FP, axis = 0)\n",
    "\n",
    "            jaccard = batch_jaccard_index(train_FP, test_FP)\n",
    "\n",
    "            print(jaccard, rec[@sim])\n",
    "            all_jaccard.append(jaccard)\n",
    "        \n",
    "        print(splitname, np.mean(all_jaccard))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0fd594",
   "metadata": {},
   "source": [
    "`` 4. Only for identical expt``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3342eea",
   "metadata": {},
   "source": [
    "`` a. Canopus and MSG ``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1f5a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1 \n",
    "compute = False \n",
    "\n",
    "if compute:\n",
    "\n",
    "    for dataset in datasets: \n",
    "\n",
    "        if dataset != \"massspecgym\": continue \n",
    "        \n",
    "        for split in splits:\n",
    "\n",
    "            similarity, test_ids, train_ids = load_pickle(os.path.join(baseline_folder, f\"{dataset}_{split}.pkl\"))\n",
    "\n",
    "            # Get jaccard list \n",
    "            all_jaccard = []\n",
    "\n",
    "            for i, test in enumerate(test_ids):\n",
    "\n",
    "                test_adduct  = dataset_info[dataset][test][\"precursor_type\"]\n",
    "                test_instrument = dataset_info[dataset][test][\"instrument_type\"]\n",
    "\n",
    "                current_similarity = similarity[i, :]\n",
    "                sort_idx = np.argsort(current_similarity)[::-1]\n",
    "                current_similarity = [current_similarity[i] for i in sort_idx]\n",
    "                current_train_ids = [train_ids[i] for i in sort_idx]\n",
    "                current_train_ids = [(idx, t) for idx, t in enumerate(current_train_ids) if \n",
    "                                    dataset_info[dataset][t][\"precursor_type\"] == test_adduct and\n",
    "                                    dataset_info[dataset][t][\"instrument_type\"] == test_instrument]\n",
    "                \n",
    "                if len(current_train_ids) == 0: continue \n",
    "                top_train = current_train_ids[0][1]\n",
    "\n",
    "                test_FP = string_to_bits(dataset_info[dataset][test][\"FPs\"][\"morgan4_4096\"])\n",
    "                train_FP = string_to_bits(dataset_info[dataset][top_train][\"FPs\"][\"morgan4_4096\"])\n",
    "\n",
    "                test_FP = np.expand_dims(test_FP, axis = 0)\n",
    "                train_FP = np.expand_dims(train_FP, axis = 0)\n",
    "                jaccard = batch_jaccard_index(train_FP, test_FP)\n",
    "\n",
    "                all_jaccard.append(jaccard)\n",
    "\n",
    "            print(dataset, split, np.mean(all_jaccard))\n",
    "\n",
    "# canopus scaffold_vanilla 0.2057512538980379\n",
    "# canopus inchikey_vanilla 0.2869633417787436\n",
    "# canopus random 0.5315042784719447\n",
    "# canopus LS 0.18068946559898919\n",
    "# massspecgym scaffold_vanilla 0.22198074741488052\n",
    "# massspecgym inchikey_vanilla 0.22648021955462153\n",
    "# massspecgym random 0.7314962309652212\n",
    "# massspecgym LS 0.1731793547288181"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5112b812",
   "metadata": {},
   "source": [
    "`` 5. Identical CF using dreaMS ``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5168182",
   "metadata": {},
   "source": [
    "`` a. Canopus and MSG``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b7724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1 \n",
    "compute = True \n",
    "\n",
    "if compute: \n",
    "\n",
    "    for dataset in datasets: \n",
    "\n",
    "        for split in splits:\n",
    "            \n",
    "            similarity, test_ids, train_ids = load_pickle(os.path.join(baseline_folder, f\"{dataset}_{split}_w_emb.pkl\"))\n",
    "\n",
    "            # Get the top k\n",
    "            top_train_idx = np.argmax(similarity, axis = 1)\n",
    "            \n",
    "            # Get jaccard list \n",
    "            all_jaccard = []\n",
    "\n",
    "            for i, test in enumerate(test_ids):\n",
    "\n",
    "                test_CF  = dataset_info[dataset][test][\"formula\"]\n",
    "\n",
    "                current_similarity = similarity[i, :]\n",
    "                sort_idx = np.argsort(current_similarity)[::-1]\n",
    "                current_similarity = [current_similarity[i] for i in sort_idx]\n",
    "                current_train_ids = [train_ids[i] for i in sort_idx]\n",
    "                current_train_ids = [(idx, t) for idx, t in enumerate(current_train_ids) if \n",
    "                                    dataset_info[dataset][t][\"formula\"] == test_CF]\n",
    "                \n",
    "                if len(current_train_ids) == 0: continue \n",
    "                top_train = current_train_ids[0][1]\n",
    "\n",
    "                test_FP = string_to_bits(dataset_info[dataset][test][\"FPs\"][\"morgan4_4096\"])\n",
    "                train_FP = string_to_bits(dataset_info[dataset][top_train][\"FPs\"][\"morgan4_4096\"])\n",
    "\n",
    "                test_FP = np.expand_dims(test_FP, axis = 0)\n",
    "                train_FP = np.expand_dims(train_FP, axis = 0)\n",
    "                jaccard = batch_jaccard_index(train_FP, test_FP)\n",
    "\n",
    "                all_jaccard.append(jaccard)\n",
    "\n",
    "            print(dataset, split, np.mean(all_jaccard))\n",
    "\n",
    "# canopus scaffold_vanilla 0.29268316215631746\n",
    "# canopus inchikey_vanilla 0.3866522313822027\n",
    "# canopus random 0.8299599868742643\n",
    "# canopus LS 0.35553839294013057\n",
    "# massspecgym scaffold_vanilla 0.47139295762321953\n",
    "# massspecgym inchikey_vanilla 0.35329460164624493\n",
    "# massspecgym random 0.9656876401618149\n",
    "# massspecgym LS 0.5272586113054561 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0172c782",
   "metadata": {},
   "source": [
    "`` b. NIST2023 ``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda021a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute = True\n",
    "\n",
    "if compute:\n",
    "\n",
    "    for splitname in splits:\n",
    "\n",
    "        results = load_pickle(f\"./cache/baselines/nist2023_{splitname}_w_emb_same_CF.pkl\")\n",
    "        \n",
    "        # Get jaccard list \n",
    "        all_jaccard = []\n",
    "        \n",
    "        for test_id, rec in tqdm(results.items()): \n",
    "\n",
    "            top_train = rec[\"train\"]\n",
    "            if top_train == \"-\": continue\n",
    "\n",
    "            train_FP = string_to_bits(load_pickle(os.path.join(data_folder, \"nist2023\", \"frags_preds\", f\"{top_train}.pkl\"))[\"FPs\"][\"morgan4_4096\"])\n",
    "            test_FP = string_to_bits(load_pickle(os.path.join(data_folder, \"nist2023\", \"frags_preds\", f\"{test_id}.pkl\"))[\"FPs\"][\"morgan4_4096\"])\n",
    "\n",
    "            test_FP = np.expand_dims(test_FP, axis = 0)\n",
    "            train_FP = np.expand_dims(train_FP, axis = 0)\n",
    "\n",
    "            jaccard = batch_jaccard_index(train_FP, test_FP)\n",
    "            all_jaccard.append(jaccard)\n",
    "        \n",
    "        print(splitname, np.mean(all_jaccard))\n",
    "\n",
    "# scaffold_vanilla 0.09020181422765648\n",
    "# inchikey_vanilla 0.09216237971678144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0500f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
