{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56fd84f7",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9412fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir -p failed for path /afs/csail.mit.edu/u/k/klingmin/.config/matplotlib: [Errno 13] Permission denied: '/afs/csail.mit.edu/u/k/klingmin/.config/matplotlib'\n",
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-3281dumr because there was an issue with the default path (/afs/csail.mit.edu/u/k/klingmin/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import json\n",
    "import torch\n",
    "import numpy as np \n",
    "from matchms import Spectrum\n",
    "from matchms.exporting import save_as_mgf\n",
    "\n",
    "from utils import load_pickle, load_json, pickle_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418f84fa",
   "metadata": {},
   "source": [
    "Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bc4433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/data/rbg/users/klingmin/projects/MS_processing/data/\"\n",
    "splits_folder = \"/data/rbg/users/klingmin/projects/MS_processing/data_splits/\"\n",
    "output_folder = \"./cache/MGF_files\"\n",
    "\n",
    "datasets = [\"canopus\", \"massspecgym\", \"nist2023\"]\n",
    "splits = [\"scaffold_vanilla\", \"inchikey_vanilla\", \"random\", \"LS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634299a9",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e057360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_bits(string): \n",
    "\n",
    "    bits = np.array([int(c) for c in string])\n",
    "\n",
    "    return bits\n",
    "\n",
    "def get_spec(id_, rec):\n",
    "    \n",
    "    peaks = sorted(rec[\"peaks\"], key = lambda x :x[\"mz\"])\n",
    "\n",
    "    spec = Spectrum(mz = np.array([p[\"mz\"] for p in peaks]),\n",
    "                    intensities = np.array([p[\"intensity\"] for p in peaks]),\n",
    "                    metadata = {\"id_\": id_,\n",
    "                                \"precursor_mz\": rec[\"precursor_MZ_final\"],\n",
    "                                \"FP\": rec[\"FPs\"][\"morgan4_4096\"]})\n",
    "    \n",
    "    return spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e01749a",
   "metadata": {},
   "source": [
    "Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fe9b289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading canopus\n",
      "Done loading MSG\n",
      "Done loading NIST2023\n"
     ]
    }
   ],
   "source": [
    "dataset_info = {} \n",
    "\n",
    "canopus = load_pickle(os.path.join(data_folder, \"canopus\", \"canopus_w_mol_info_w_frag_CF_preds.pkl\"))\n",
    "canopus = {str(r[\"id_\"]) : r for r in canopus}\n",
    "print(\"Done loading canopus\")\n",
    "\n",
    "massspecgym = load_pickle(os.path.join(data_folder, \"massspecgym\", \"massspecgym_w_mol_info_w_frag_CF_preds.pkl\"))\n",
    "massspecgym = {str(r[\"id_\"]) : r for r in massspecgym}\n",
    "print(\"Done loading MSG\")\n",
    "\n",
    "nist2023 = load_pickle(os.path.join(data_folder, \"nist2023\", \"nist2023_w_mol_info_w_frag_CF_preds.pkl\"))\n",
    "nist2023 = {r[\"id_\"] : r for r in nist2023}\n",
    "print(\"Done loading NIST2023\")\n",
    "\n",
    "dataset_info[\"canopus\"] = canopus\n",
    "dataset_info[\"massspecgym\"] = massspecgym\n",
    "dataset_info[\"nist2023\"] = nist2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe6eb6e",
   "metadata": {},
   "source": [
    "Get the MGF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "949cdfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated the spec for nist2023, scaffold_vanilla (train). Length: 643637\n",
      "Generated the spec for nist2023, scaffold_vanilla (test). Length: 137840\n",
      "Generated the spec for nist2023, inchikey_vanilla (train). Length: 643637\n",
      "Generated the spec for nist2023, inchikey_vanilla (test). Length: 137840\n",
      "Generated the spec for nist2023, random (train). Length: 643521\n",
      "Generated the spec for nist2023, random (test). Length: 137898\n",
      "Generated the spec for nist2023, LS (train). Length: 285823\n",
      "Generated the spec for nist2023, LS (test). Length: 18333\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets: \n",
    "\n",
    "    for split in splits: \n",
    "\n",
    "        current_folder = os.path.join(output_folder, dataset, split)\n",
    "        if not os.path.exists(current_folder): os.makedirs(current_folder)\n",
    "        train_MGF_path = os.path.join(current_folder, \"train.mgf\")\n",
    "        test_MGF_path = os.path.join(current_folder, \"test.mgf\")\n",
    "\n",
    "        split_file = load_json(os.path.join(splits_folder, dataset, \"splits\", split + \".json\"))\n",
    "\n",
    "        if not os.path.exists(train_MGF_path):\n",
    "\n",
    "            train = split_file[\"train\"]\n",
    "            train = [get_spec(f.replace(\".pkl\", \"\"), dataset_info[dataset][f.replace(\".pkl\", \"\")]) for f in train]\n",
    "            save_as_mgf(train, train_MGF_path)\n",
    "            print(f\"Generated the spec for {dataset}, {split} (train). Length: {len(train)}\")\n",
    "        \n",
    "        if not os.path.exists(test_MGF_path):\n",
    "\n",
    "            test = split_file[\"test\"]\n",
    "            test = [get_spec(f.replace(\".pkl\", \"\"), dataset_info[dataset][f.replace(\".pkl\", \"\")]) for f in test]\n",
    "            save_as_mgf(test, test_MGF_path)\n",
    "            print(f\"Generated the spec for {dataset}, {split} (test). Length: {len(test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa27f6c0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
